{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Scraping bio/characteristic data from Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and parameters\n",
    "import requests\n",
    "import bs4\n",
    "\n",
    "prefix=\"https://en.wikipedia.org/wiki/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Define Scraping function\n",
    "Function takes the following arguments:\n",
    "-  Article List - A list of the articles you want to scrape from\n",
    "-  Characteristics - The categories/characteristics to scrape for each article (coming from the bio/info box in the top right of the article)\n",
    "-  Outfile - format for the output file, two files will be created 'filename.csv' with the collected data and 'filename_errors.log' that keeps track of the holes in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_scrape(article_list=['My Chemical Romance'], char=['Genres'],outfile='wiki_scrape'):\n",
    "    \n",
    "    open(outfile+'.csv','w').close()\n",
    "    open(outfile+'_errors.log','w').close()\n",
    "\n",
    "\n",
    "    for article in article_list:\n",
    "        char_count= [0]*len(char)\n",
    "        suffix=article.replace(\" \",\"_\")\n",
    "        url = prefix + suffix\n",
    "\n",
    "        soup=bs4.BeautifulSoup(requests.get(url).text, 'lxml')\n",
    "        \n",
    "        # Find the info table\n",
    "        table= soup.find('table')\n",
    "        wiki_dict={}\n",
    "\n",
    "        rows=table.find_all('tr')\n",
    "        for row in rows:\n",
    "            row_title=row.find('th')\n",
    "            try:\n",
    "                if row_title.text in char:\n",
    "                    wiki_dict[row.find('th').text]=row.find('td').text\n",
    "                    char_count[char.index(row_title.text)]=1\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        with open(outfile+'.csv', \"a\") as wfile:\n",
    "            article_output= '\"'  + article + '\",\"' + url + '\",\"' + str(wiki_dict) + '\"'\n",
    "            wfile.write(str(article_output)+ \"\\n\")\n",
    "\n",
    "        if char_count != [1]*len(char):\n",
    "            with open(outfile+'_errors.log', \"a\") as wfile:\n",
    "                for count in char_count:\n",
    "                    if count == 0:\n",
    "                        wfile.write(\"Error: Couldn't find \" + \\\n",
    "                                    \"'\" + char[char_count.index(count)] + \"'\"+ \\\n",
    "                                    \" for \" + \"'\" + article + \"'\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "halftime=['Coldplay', 'Beyonce', 'Bruno Mars','Katy Perry', 'Lenny Kravitz' ,'Missy Elliott','Bruno Mars', 'Red Hot Chili Peppers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_scrape(halftime,['Born','Died','Genres', 'Children'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coldplay \n",
      "\n",
      "\n",
      "Alternative rock\n",
      "pop rock\n",
      "post-Britpop\n",
      "pop\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "newthing=[]\n",
    "with open('wiki_scrape.csv','r') as f:\n",
    "    stuff=csv.reader(f)\n",
    "    for row in stuff:\n",
    "        newthing.append(row)\n",
    "dic=eval(newthing[0][2])\n",
    "print(newthing[0][0],dic['Genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare text allowing for mistakes\n",
    "def raw(string):\n",
    "    out=string.rstrip().lstrip().lower().replace('  ', ' ')\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mUse'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' mUse'.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=bs4.BeautifulSoup(requests.get(\"https://en.wikipedia.org/wiki/Muse_(disambiguation)\").text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_disambig(soup):\n",
    "    if soup.find_all('a',attrs={'title':'Help:Disambiguation'}) == []:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_article(soup):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# More features to build\n",
    "\n",
    "### Page lookup right:\n",
    "# Disambigution - if 'Disambigution pages' is in the bottom, then print ambiguity error\n",
    "# Search result - select top result, if no character matches return special error?\n",
    "\n",
    "# Just supply list of URLs (to reduce ambiguity)\n",
    "\n",
    "# Formatting etc, save as dictionary rather than output, etc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Scrape Tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/President_of_Ireland\"\n",
    "\n",
    "browser = Browser('chrome', headless=False)\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Nicki_Minaj_discography\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Find the actual useful tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of studio albums, with selected chart positions, sales figures and certifications\n",
      "List of reissued albums\n",
      "List of compilation albums, with selected chart positions and certifications\n",
      "List of mixtapes, with selected details\n",
      "List of singles as lead artist, with selected chart positions and certifications, showing year released and album name\n",
      "List of singles as featured artist, with selected chart positions and certifications, showing year released and album name\n",
      "List of promotional singles, with selected chart positions and certifications, showing year released and album name\n",
      "List of songs, with selected chart positions and certifications, showing year released and album name\n",
      "List of non-single guest appearances, with other performing artists, showing year released and album name\n"
     ]
    }
   ],
   "source": [
    "# Find the actual useful tables (ones that start with 'wikitable')\n",
    "tables = (tab for tab in browser.find_by_tag('table') if tab._element.get_attribute('class').split()[0] == 'wikitable')\n",
    "\n",
    "# May not have a caption\n",
    "for tab in tables:\n",
    "    try:\n",
    "        cap = tab.find_by_tag('caption').text\n",
    "        print(cap)\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "rows = list(tab.find_by_tag('tr'))\n",
    "\n",
    "\n",
    "for i, row in enumerate(rows):\n",
    "    row_data = []\n",
    "    \n",
    "    # First row may be headers, slightly different tag\n",
    "    if i == 0:\n",
    "        \n",
    "        if row.find_by_tag('th'):\n",
    "            cells = row.find_by_tag('th')\n",
    "            for cell in cells:\n",
    "                row_data.append(cell.text)\n",
    "                \n",
    "            data.append(row_data)\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "    else:    \n",
    "        cells = row.find_by_tag('td')\n",
    "\n",
    "        for cell in cells:\n",
    "            row_data.append(cell.text)\n",
    "\n",
    "        data.append(row_data)\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_scrape(url):\n",
    "        \n",
    "    from splinter import Browser\n",
    "    browser = Browser('chrome', headless=True)\n",
    "    browser.visit(url)\n",
    "    \n",
    "    scraped_tables = []\n",
    "    \n",
    "    # Find the tables using find in splinter\n",
    "    tables = (tab for tab in browser.find_by_tag('table') if tab._element.get_attribute('class').split()[0] == 'wikitable')\n",
    "    \n",
    "    for tab in tables:\n",
    "        t_dict = {}\n",
    "        \n",
    "        # Not every table has a caption, if there is one capture it\n",
    "        try:\n",
    "            t_dict['caption'] = tab.find_by_tag('caption').text\n",
    "        except:\n",
    "            t_dict['caption'] = \"\"\n",
    "        \n",
    "        # Now the data\n",
    "        data = []\n",
    "        # Locate the rows of the table\n",
    "        rows = list(tab.find_by_tag('tr'))\n",
    "\n",
    "        for i, row in enumerate(rows):\n",
    "            row_data = []\n",
    "\n",
    "            # First row may be headers, slightly different tag\n",
    "            if i == 0:\n",
    "\n",
    "                # In which case we will append that data and continue on to next in iteration\n",
    "                if row.find_by_tag('th'):\n",
    "                    cells = row.find_by_tag('th')\n",
    "                    for cell in cells:\n",
    "                        row_data.append(cell.text)\n",
    "                    data.append(row_data)\n",
    "                    continue\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            # Regular case for all other rows (first row may fall into here if none header row)\n",
    "            cells = row.find_by_tag('td')\n",
    "\n",
    "            for cell in cells:\n",
    "                row_data.append(cell.text)\n",
    "            data.append(row_data)\n",
    "\n",
    "        t_dict['data'] = data\n",
    "        \n",
    "        scraped_tables.append(t_dict)\n",
    "        \n",
    "    return(scraped_tables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = table_scrape(\"https://en.wikipedia.org/wiki/Nicki_Minaj_discography\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of studio albums, with selected chart positions, sales figures and certifications\n",
      "List of reissued albums\n",
      "List of compilation albums, with selected chart positions and certifications\n",
      "List of mixtapes, with selected details\n",
      "List of singles as lead artist, with selected chart positions and certifications, showing year released and album name\n",
      "List of singles as featured artist, with selected chart positions and certifications, showing year released and album name\n",
      "List of promotional singles, with selected chart positions and certifications, showing year released and album name\n",
      "List of songs, with selected chart positions and certifications, showing year released and album name\n",
      "List of non-single guest appearances, with other performing artists, showing year released and album name\n"
     ]
    }
   ],
   "source": [
    "for tab in test:\n",
    "    print(tab['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'caption': '',\n",
       "  'data': [['No.',\n",
       "    'Name\\n(Birth–Death)',\n",
       "    'Portrait',\n",
       "    'Previous service',\n",
       "    'Term of office',\n",
       "    'Nominated by',\n",
       "    'Election'],\n",
       "   ['1',\n",
       "    'Douglas Hyde\\n(1860–1949)',\n",
       "    '',\n",
       "    'Senator\\n(1925, 1938)',\n",
       "    '25 June 1938',\n",
       "    '24 June 1945',\n",
       "    'All-party nomination',\n",
       "    '1938'],\n",
       "   ['2',\n",
       "    \"Seán T. O'Kelly\\n(1882–1966)\",\n",
       "    '',\n",
       "    'Tánaiste\\n(1932–1945)',\n",
       "    '25 June 1945',\n",
       "    '24 June 1959',\n",
       "    'Fianna Fáil',\n",
       "    '1945'],\n",
       "   ['Himself[n 3]', '1952'],\n",
       "   ['3',\n",
       "    'Éamon de Valera\\n(1882–1975)',\n",
       "    '',\n",
       "    'Taoiseach\\n(1932–1948, 1951–1954, 1957–1959)',\n",
       "    '25 June 1959',\n",
       "    '24 June 1973',\n",
       "    'Fianna Fáil',\n",
       "    '1959'],\n",
       "   ['Fianna Fáil[n 4]', '1966'],\n",
       "   ['4',\n",
       "    'Erskine H. Childers\\n(1905–1974)',\n",
       "    '',\n",
       "    'Tánaiste\\n(1969–1973)',\n",
       "    '25 June 1973',\n",
       "    '17 November 1974',\n",
       "    'Fianna Fáil',\n",
       "    '1973'],\n",
       "   ['5',\n",
       "    'Cearbhall Ó Dálaigh[53]\\n(1911–1978)',\n",
       "    '',\n",
       "    'Chief Justice of Ireland\\n(1961–1973)',\n",
       "    '19 December 1974',\n",
       "    '22 October 1976',\n",
       "    'All-party nomination',\n",
       "    '1974'],\n",
       "   ['6',\n",
       "    'Patrick Hillery\\n(1923–2008)',\n",
       "    '',\n",
       "    'European Commissioner for Social Affairs\\n(1973–1976)',\n",
       "    '3 December 1976',\n",
       "    '2 December 1990',\n",
       "    'Fianna Fáil',\n",
       "    '1976'],\n",
       "   ['Fianna Fáil', '1983'],\n",
       "   ['7',\n",
       "    'Mary Robinson\\n(1944–)',\n",
       "    '',\n",
       "    'Senator\\n(1969–1989)',\n",
       "    '3 December 1990',\n",
       "    '12 September 1997',\n",
       "    'Labour Party',\n",
       "    '1990'],\n",
       "   [\"Workers' Party\"],\n",
       "   ['Independent'],\n",
       "   ['8',\n",
       "    'Mary McAleese\\n(1951–)',\n",
       "    '',\n",
       "    'Reid Professor of Criminal law, Criminology and Penology at Trinity College Dublin',\n",
       "    '11 November 1997',\n",
       "    '10 November 2011',\n",
       "    'Fianna Fáil',\n",
       "    '1997'],\n",
       "   ['Herself', '2004'],\n",
       "   ['9',\n",
       "    'Michael D. Higgins\\n(1941–)',\n",
       "    '',\n",
       "    'Minister for Arts, Culture and Gaeltacht\\n(1993–1997)',\n",
       "    '11 November 2011',\n",
       "    'Incumbent',\n",
       "    'Labour Party',\n",
       "    '2011'],\n",
       "   ['Himself', '2018']]}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_scrape(\"https://en.wikipedia.org/wiki/President_of_Ireland\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
